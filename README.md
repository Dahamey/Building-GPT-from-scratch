We build a Generatively Pretrained Transformer (GPT) a Decoder-Only Transformer, following the paper "Attention is All You Need" and OpenAI's GPT-2 / GPT-3.
